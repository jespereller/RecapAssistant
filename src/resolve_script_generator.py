import os
import random
import time
import math
import traceback
from collections import defaultdict
from tkinter import filedialog, messagebox
import reprlib

# Using reprlib to handle potentially large data structures safely
safe_repr = reprlib.Repr()
safe_repr.maxlist = 5000 # Limit list representation length
safe_repr.maxdict = 5000 # Limit dict representation length
safe_repr.maxstring = 5000 # Limit string representation length

def create_script(estimated_tempo, frame_duration, merged_moments, scene_moments,
                  video_files, audio_file_path, audio_start_offset,
                  selected_style,
                  audio_processed, video_processed):
    """
    Generates the DaVinci Resolve Python script dynamically.
    Uses ORIGINAL duration logic (Style choice constrained by detected duration).
    NO Snap-up logic. Min detected duration >= 2 beats applied before script.
    NO overlap resolution performed before appending. Handles timecode duration.
    Includes Loose randomization. Assumes MediaPipe detection.
    """

    # Input Validation
    if not audio_processed or not video_processed:
        messagebox.showerror("Error", "Process audio & video first.")
        return
    if frame_duration is None or frame_duration <= 0:
        messagebox.showerror("Error", "Audio beat duration invalid.")
        return
    if not video_files or not audio_file_path:
        messagebox.showerror("Error", "Audio/Video file info missing.")
        return
    if not merged_moments and not scene_moments:
        messagebox.showwarning("Warning", "No candidate moments found. Script may create empty V1.")
    # Style selection check happens in main.py before calling this

    # Configuration Definition
    cfg = {
        "default_fps": 24.0,
        "min_clip_duration_frames": 12, # Minimum allowed clip duration AFTER clamping
        "target_video_track": 1,
        "target_audio_track": 2,
        "delete_a1_track": True,
        "style_definitions": { # Editing style definitions for script
             "Fast-paced": {"base_multipliers": [2, 4, 8],"weights": [0.2, 0.4, 0.4]},
             "Standard": {"base_multipliers": [2, 4, 8, 16],"weights": [0.1, 0.4, 0.4, 0.1]},
             "Relaxed": {"base_multipliers": [4, 8, 16],"weights": [0.2, 0.4, 0.4]},
             "_Default": {"base_multipliers": [2, 4, 8, 16],"weights": [0.1, 0.3, 0.3, 0.3]}
        }
    }

    # Data Formatting for Template
    try:
        # Use safe_repr for potentially large lists/dicts
        py_video_files_str = safe_repr.repr(video_files)
        py_people_moments_str = safe_repr.repr(merged_moments or [])
        py_other_scene_moments_str = safe_repr.repr(scene_moments or [])
        py_audio_file_path_str = safe_repr.repr(audio_file_path)
        py_editing_style_str = safe_repr.repr(selected_style)
        py_audio_start_offset_str = f"{float(audio_start_offset):.4f}" # Format offset as float string
        py_style_definitions_str = safe_repr.repr(cfg["style_definitions"])
        bpm_comment = f"# ANALYSIS_ESTIMATED_BPM = {estimated_tempo:.2f}" if estimated_tempo else "# BPM Not Available"
        frame_dur_var = f"ANALYSIS_FRAME_DURATION_SECONDS = {frame_duration:.4f}" if frame_duration else "ANALYSIS_FRAME_DURATION_SECONDS = 0.0"

    except Exception as e:
        messagebox.showerror("Error", f"Data formatting error before script generation: {e}\n\n{traceback.format_exc()}")
        return

    # Python Script Template itself - includes logging aswell, this first version is pretty hardcoded though. Potential improvements in future versions after the thesis is complete
    python_script_template = f"""
# DaVinci Resolve Python Script Generated by Analysis Tool vOrigNoSnapNoOverlap
# Uses original duration logic, no overlap resolution, includes randomization.
import os, sys, random, math, time, traceback
from collections import defaultdict

# --- Analysis Info (Passed from Generator) ---
ANALYSIS_AUDIO_FILE = {py_audio_file_path_str}
{bpm_comment}
{frame_dur_var}
ANALYSIS_EDITING_STYLE = {py_editing_style_str}
ANALYSIS_AUDIO_START_OFFSET_SEC = {py_audio_start_offset_str}

# --- Data (Candidate Moments Passed from Generator) ---
INPUT_VIDEO_FILES = {py_video_files_str}
INPUT_PEOPLE_MOMENTS = {py_people_moments_str}
INPUT_OTHER_SCENE_MOMENTS = {py_other_scene_moments_str}

# --- Configuration (Passed from Generator) ---
FRAMES_PER_SECOND = {cfg['default_fps']}; MIN_CLIP_DURATION_FRAMES = {cfg['min_clip_duration_frames']}
TARGET_VIDEO_TRACK = {cfg['target_video_track']}; TARGET_AUDIO_TRACK = {cfg['target_audio_track']}; DELETE_A1 = {cfg['delete_a1_track']}
STYLE_DEFINITIONS = {py_style_definitions_str}

# --- Helper Functions ---
def s2f(s, fps): return int(round(s * fps))
def f2s(f, fps): return float(f) / fps if fps > 0 else 0.0
def timecode_to_frames(tc_str, fps):
    '''Converts HH:MM:SS:FF timecode string to frame count.'''
    if not isinstance(tc_str, str) or tc_str.count(':') != 3: print(f"Warn: Invalid timecode format: {{tc_str}}"); return 0
    try: parts = tc_str.split(':'); h, m, s, f = map(int, parts); total_seconds = (h * 3600) + (m * 60) + s; total_frames = int(round(total_seconds * fps)) + f; return total_frames
    except ValueError: print(f"Warn: Could not parse timecode components: {{tc_str}}"); return 0
    except Exception as e: print(f"Warn: Error parsing timecode '{{tc_str}}': {{e}}"); return 0

# --- Main Function (Runs Inside Resolve) ---
def create_resolve_timeline(video_files, people_moments, other_moments, audio_path, style, offset):
    print("--- Starting Resolve Script ---"); timeline = None; project = None; pool = None
    global FRAMES_PER_SECOND, MIN_CLIP_DURATION_FRAMES
    try: # Initialize Resolve API handles and get FPS
        try: resolve = app.GetResolve()
        except NameError: print("\\nERROR: 'app' object not found. Run from Resolve Console."); return
        pm = resolve.GetProjectManager(); project = pm.GetCurrentProject()
        if not project: raise Exception("No project open")
        pool = project.GetMediaPool(); root = pool.GetRootFolder()
        if not pool: raise Exception("Cannot get Media Pool")
        print(f"Project: {{project.GetName()}}")
        fps_setting = project.GetSetting('timelineFrameRate')
        if fps_setting:
            try: fps = float(fps_setting); FRAMES_PER_SECOND = fps if fps > 0 else FRAMES_PER_SECOND
            except ValueError: pass # Keep default if setting is invalid
        print(f"Using FPS: {{FRAMES_PER_SECOND}}")
        beat_s = ANALYSIS_FRAME_DURATION_SECONDS
        beat_f = max(1, s2f(beat_s, FRAMES_PER_SECOND)) if beat_s > 0 else -1 # Beat duration in frames
        if beat_f <= 0: print("WARNING: Beat duration is invalid (<= 0 frames), duration logic may fail.")
        print(f"Beat Duration: {{beat_f}} frames")
    except Exception as e: print(f"Init Error: {{e}}"); traceback.print_exc(); return

    try: # Create a new Timeline
        ts = time.strftime("%Y%m%d_%H%M%S"); audio_base = os.path.splitext(os.path.basename(audio_path))[0]
        name = f"Edited_{{audio_base}}_{{style}}_{{ts}}_NoOverlap" # Indicate no overlap logic used
        print(f"Creating timeline: {{name}}"); timeline = pool.CreateEmptyTimeline(name)
        if not timeline: raise Exception("Timeline creation failed.")
        if not project.SetCurrentTimeline(timeline): print("Warning: Could not set timeline as current.")
        start_f = timeline.GetStartFrame(); print(f"Timeline Start Frame: {{start_f}}")
    except Exception as e: print(f"Timeline Error: {{e}}"); traceback.print_exc(); return

    try: # Locate Media files in the Media Pool
        print("Locating Media in Pool..."); lookup = {{}}; audio_item = None; all_ok = True
        def find_media(folder, fname): # Recursive search function
            for clip in folder.GetClipList() or []:
                if clip.GetName()==fname: return clip
                try: # Check other properties if name doesn't match directly
                    if clip.GetClipProperty("File Name")==fname: return clip
                    fp = clip.GetClipProperty("File Path");
                    if fp and os.path.basename(fp)==fname: return clip
                except: pass # Ignore errors during property checks
            for sub in folder.GetSubFolderList() or []: # Recurse into subfolders
                found = find_media(sub, fname);
                if found: return found
            return None
        # Import and find video files
        unique_vids = list(set(video_files))
        if unique_vids: pool.ImportMedia(unique_vids) # Import necessary video files
        for vp in unique_vids:
            base = os.path.basename(vp); item = find_media(root, base)
            if item: lookup[base] = item # Store found MediaPoolItem
            else: print(f"ERROR: Video not found in Media Pool: {{base}}"); all_ok = False
        # Import and find audio file
        audio_base = os.path.basename(audio_path); pool.ImportMedia([audio_path])
        audio_item = find_media(root, audio_base)
        if not audio_item: print(f"ERROR: Audio not found in Media Pool: {{audio_base}}"); all_ok = False
        if not all_ok: print("Aborting due to missing media file(s)."); return
        print("Media located successfully.")
    except Exception as e: print(f"Media Location/Import Error: {{e}}"); traceback.print_exc(); return

    # --- Prepare Clips based on Moments and Style ---
    potential_clips = []
    def prep_clip(moment, label, lookup, fps, beat_f, style):
        # Calculates final clip duration based on style, beat, and original duration.
        # Clamps to source duration and minimum duration.
        try:
            s_sec, e_sec, _, fname = moment # Unpack moment data
            base = os.path.basename(fname); item = lookup.get(base) # Find MediaPoolItem
            if not item: item = next((i for i in lookup.values() if i.GetName()==base), None) # Fallback name check
            if not item: print(f"Warn: MediaPoolItem not found for '{{base}}'. Skip preparing clip."); return None
            s_f = s2f(s_sec, fps); e_f_orig = s2f(e_sec, fps); dur_f_orig = e_f_orig - s_f # Original start/end/duration in frames

            # Get source duration from MediaPoolItem properties, handling different formats
            src_dur_frames = 0
            try:
                duration_prop = item.GetClipProperty("Duration") # Returns timecode string (HH:MM:SS:FF) or frames int
                if isinstance(duration_prop, (int, float)): src_dur_frames = int(duration_prop)
                elif isinstance(duration_prop, str) and ':' in duration_prop: src_dur_frames = timecode_to_frames(duration_prop, fps)
                elif isinstance(duration_prop, str) and duration_prop.isdigit(): src_dur_frames = int(duration_prop) # Handle plain frame number string
                else: print(f"Warn: Unknown format for Duration property of '{{base}}': {{duration_prop}} (Type: {{type(duration_prop)}}). Cannot clamp duration.")
            except Exception as e: print(f"Warn: Could not get or parse Duration property for '{{base}}': {{e}}. Cannot clamp duration.")

            # Calculate duration based on style, beats, and original duration
            dur_f = 0; chosen_multiplier = 1
            style_params = STYLE_DEFINITIONS.get(style, STYLE_DEFINITIONS.get("_Default")) # Get style parameters
            base_multipliers = sorted(style_params.get("base_multipliers", [1])) # Ensure sorted multipliers
            base_weights = style_params.get("weights")

            # Original constrained duration logic (No snap-up)
            if beat_f > 0 and dur_f_orig >= beat_f: # Only apply multipliers if clip >= 1 beat
                max_m = math.floor(dur_f_orig / beat_f) # Max multiplier possible based on original duration
                mults = []; valid_base_indices = []
                # Find valid multipliers based on max_m
                for i, m in enumerate(base_multipliers):
                    if max_m >= m: mults.append(m); valid_base_indices.append(i)
                if not mults: # Ensure at least one multiplier is selected (smallest)
                    mults = [base_multipliers[0]] if base_multipliers else [1]; valid_base_indices = [0] if base_multipliers else []
                # Determine weights for valid multipliers
                weights = None
                if base_weights is not None and len(base_weights) == len(base_multipliers) and valid_base_indices:
                    temp_weights = [base_weights[i] for i in valid_base_indices]; sum_w = sum(temp_weights)
                    if sum_w > 0: weights = [w / sum_w for w in temp_weights] # Normalize weights
                # Choose multiplier (weighted or random)
                if mults:
                    if weights and len(weights) == len(mults):
                         try: chosen_multiplier = random.choices(mults, weights=weights, k=1)[0]
                         except Exception: chosen_multiplier = random.choice(mults) # Fallback if weights invalid
                    else: chosen_multiplier = random.choice(mults) # Uniform random if no weights
                dur_f = chosen_multiplier * beat_f # Final duration based on multiplier
            elif dur_f_orig > 0: # If less than a beat, use original duration
                dur_f = dur_f_orig
            else: # Fallback for zero original duration (should not happen with filtering)
                dur_f = s2f(1.0, fps) # Default to 1 second

            # Clamp duration: Apply minimum and clamp to source duration
            dur_f = max(MIN_CLIP_DURATION_FRAMES, dur_f) # Ensure minimum duration
            e_f = s_f + dur_f # Calculate end frame based on duration
            if src_dur_frames > 0: # If source duration is known, clamp end frame
                e_f = min(e_f, src_dur_frames)
                dur_f = max(MIN_CLIP_DURATION_FRAMES, e_f - s_f) # Recalculate duration after clamping end
                e_f = s_f + dur_f # Ensure end frame matches clamped duration
                e_f = min(e_f, src_dur_frames) # Final clamp on end frame (redundant?)

            if e_f <= s_f: return None # Skip if duration is zero or negative after clamping

            # Return dictionary structure for Resolve's AppendToTimeline
            # Include helper keys for later randomization/processing
            return {{"mediaPoolItem": item, "startFrame": s_f, "endFrame": e_f, "duration": dur_f,
                     "mediaType": 1, "trackIndex": TARGET_VIDEO_TRACK, "source_file": base}}
        except Exception as e: print(f"Error Preparing Clip ('{{label}}', '{{fname}}'): {{e}}"); traceback.print_exc(); return None
    # --- End of prep_clip ---

    # Process all candidate moments passed from the generator
    print(f"Preparing potential clips (Min Final Duration: {{MIN_CLIP_DURATION_FRAMES}} frames)...")
    all_candidate_moments = []
    # Combine people and other moments with their labels
    for m in INPUT_PEOPLE_MOMENTS: all_candidate_moments.append({{"label":"People", "data":m}})
    for m in INPUT_OTHER_SCENE_MOMENTS: all_candidate_moments.append({{"label":m[2], "data":m}})
    # Sort by original start time (optional, but can help if randomization is removed later)
    # all_candidate_moments.sort(key=lambda x: x['data'][0])
    # Prepare each moment using the prep_clip function
    for item in all_candidate_moments:
        clip_info = prep_clip(item['data'], item['label'], lookup, FRAMES_PER_SECOND, beat_f, style)
        if clip_info: potential_clips.append(clip_info) # Collect successfully prepared clips
    print(f"Prepared {{len(potential_clips)}} potential video clips.")

    # --- Randomization by Source File ---
    final_clips_to_append = []
    if not potential_clips:
        print("No prepared clips to randomize or append.")
    else:
        print(f"Randomizing order of {{len(potential_clips)}} prepared clips (grouping by source file)...")
        grouped_clips = defaultdict(list)
        # Group clips by their source filename
        for clip in potential_clips:
            grouped_clips[clip.get('source_file', 'UnknownSource')].append(clip)

        # Shuffle the order of the source files
        source_files_ordered = list(grouped_clips.keys())
        random.shuffle(source_files_ordered)

        # Rebuild the list in the new shuffled source order
        randomized_clips = []
        for source_file in source_files_ordered:
            clips_from_source = grouped_clips[source_file]
            # Optional: Shuffle clips *within* each source file group
            # random.shuffle(clips_from_source)
            randomized_clips.extend(clips_from_source)

        final_clips_to_append = randomized_clips # This is the final list to be appended
        print(f"Randomization complete. Final clip count for timeline: {{len(final_clips_to_append)}}")
    # --- End Randomization ---

    # Append the final list of video clips to the timeline
    v1_end = start_f # Keep track of the end frame of the video track
    if final_clips_to_append:
        print(f"Appending {{len(final_clips_to_append)}} final clips to Video Track {{TARGET_VIDEO_TRACK}}...")
        # Prepare list for Resolve API (remove helper keys)
        clips_for_resolve = []
        for clip in final_clips_to_append:
             resolve_clip = clip.copy()
             resolve_clip.pop('duration', None) # Remove internal 'duration' key
             resolve_clip.pop('source_file', None) # Remove internal 'source_file' key
             clips_for_resolve.append(resolve_clip)
        # Call Resolve API to append clips
        try: added_clips = pool.AppendToTimeline(clips_for_resolve)
        except Exception as e: print(f"Video Append Error: {{e}}"); traceback.print_exc(); added_clips = None
        # Verify and update end frame
        if added_clips:
            timeline_clips = timeline.GetItemListInTrack("video", TARGET_VIDEO_TRACK)
            if timeline_clips: v1_end = timeline_clips[-1].GetEnd(); print(f"Video Track {{TARGET_VIDEO_TRACK}} ends at frame: {{v1_end}}")
            else: print("Warning: Could not retrieve clips from timeline after append to confirm end frame.")
        else: print("Warning: Video append failed or returned no clips.")
    # else: Handled by initial check on final_clips_to_append

    # Append the audio track
    if audio_item:
        print(f"Preparing audio track (Audio Start Offset: {{offset:.3f}}s)...")
        try:
            # Ensure target audio track exists
            num_a = timeline.GetTrackCount("audio");
            if num_a < TARGET_AUDIO_TRACK:
                for i in range(TARGET_AUDIO_TRACK - num_a): timeline.AddTrack("audio","stereo") # Add stereo tracks if needed
            # Calculate audio start/end based on offset and video track duration
            aud_s_f = max(0, s2f(offset, FRAMES_PER_SECOND)); aud_e_f = None
            if v1_end > start_f: # Only calculate end if video clips were added
                vid_track_duration = v1_end - start_f; calc_e = aud_s_f + vid_track_duration
                src_dur = 0
                try: src_dur = int(audio_item.GetClipProperty("Duration")) # Get audio source duration (frames)
                except: pass
                if src_dur > 0: aud_e_f = min(calc_e, src_dur) # Clamp end to audio source duration
                else: aud_e_f = calc_e # Use calculated end if source duration unknown
                if aud_e_f <= aud_s_f: aud_e_f = aud_s_f + 1 # Ensure end > start
            # Prepare dictionary for audio append
            aud_info = {{"mediaPoolItem": audio_item, "startFrame": aud_s_f, "mediaType": 2, "trackIndex": TARGET_AUDIO_TRACK}}
            if aud_e_f is not None and aud_e_f > aud_s_f: aud_info['endFrame'] = aud_e_f # Add endFrame if calculated
            print(f"Appending audio clip: {{aud_info}}")
            if pool.AppendToTimeline([aud_info]): print("Audio appended successfully.")
            else: print("Warning: Audio append failed.")
        except Exception as e: print(f"Audio Append Error: {{e}}"); traceback.print_exc()
    else: print("Audio item missing, cannot append audio track.")

    # Delete original A1 audio track if configured
    if DELETE_A1:
        try:
            if timeline.GetTrackCount("audio") >= 1:
                if timeline.DeleteTrack("audio", 1): print("Original Audio Track 1 deleted.")
                # else: print("Failed to delete A1 (already gone?)") # Optional message
        except Exception as e: print(f"Warning: Failed to delete Audio Track 1: {{e}}")

    print("--- Resolve Script Finished ---")

# --- Run Block (Executes if script is run directly in Resolve) ---
if __name__ == '__main__':
    # Check if running within Resolve context by looking for 'app'
    if 'app' in locals() or 'app' in globals():
        # Call the main function using the data embedded in the script
        create_resolve_timeline(
            INPUT_VIDEO_FILES, INPUT_PEOPLE_MOMENTS, INPUT_OTHER_SCENE_MOMENTS,
            ANALYSIS_AUDIO_FILE, ANALYSIS_EDITING_STYLE, ANALYSIS_AUDIO_START_OFFSET_SEC
        )
    else: print("\\nERROR: This script must be run from the DaVinci Resolve Python Console.")

""" # End of python_script_template

    # save the generated script
    file_path = filedialog.asksaveasfilename(
        defaultextension=".py",
        filetypes=[("Python Script", "*.py")],
        title="Save DaVinci Resolve Script"
    )
    if not file_path:
        messagebox.showinfo("Cancelled", "Script creation cancelled by user.")
        return
    try:
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(python_script_template)
        messagebox.showinfo("Success", f"Resolve script saved successfully to:\n{file_path}\n\nTo run: Place this script in the Resolve 'Scripts/Utility' folder and run from Resolve's Scripts menu.")
    except Exception as e:
        messagebox.showerror("Error", f"Failed to save script to disk:\n{e}\n\n{traceback.format_exc()}")
